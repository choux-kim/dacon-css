{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ae_xgboost",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_LXuBamNHS9",
        "outputId": "9285f83a-4c6b-40fd-d793-5c5d5eab3acc"
      },
      "source": [
        "!pip install -q Kaggler"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10kB 22.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 30.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 26.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 40kB 20.5MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 19.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 61kB 15.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 71kB 13.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 81kB 14.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 92kB 13.9MB/s eta 0:00:01\r\u001b[K     |████                            | 102kB 13.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 112kB 13.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 122kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 133kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 143kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 153kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 163kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 174kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 184kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 194kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 204kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 215kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 225kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 235kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 245kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 256kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 266kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 276kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 286kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 296kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 307kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 317kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 327kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 337kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 348kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 358kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 368kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 378kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 389kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 399kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 409kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 419kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 430kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 440kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 450kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 460kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 471kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 481kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 491kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 501kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 512kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 522kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 532kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 542kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 552kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 563kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 573kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 583kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 593kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 604kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 614kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 624kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 634kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 645kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 655kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 665kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 675kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 686kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 696kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 706kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 716kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 727kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 737kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 747kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 757kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 768kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 778kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 788kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 798kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 808kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 819kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 829kB 13.6MB/s \n",
            "\u001b[?25h  Building wheel for Kaggler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ml-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVUzLk3SAEza"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
        "import tensorflow as tf\n",
        "\n",
        "from kaggler.preprocessing import LabelEncoder\n",
        "from kaggler.model import AutoLGB\n",
        "from xgboost import XGBClassifier\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "import kaggler"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcdFLKdTAyj7",
        "outputId": "888092b2-cf7f-46b2-881a-7f19bd67464a"
      },
      "source": [
        "index_col = 'index'\n",
        "target_col = 'credit'\n",
        "\n",
        "X = pd.read_csv('train.csv', index_col=index_col, encoding='utf-8').drop(columns=['credit'])\n",
        "y = pd.read_csv('train.csv', index_col=index_col, encoding='utf-8')['credit']\n",
        "X_test = pd.read_csv('test.csv', index_col=index_col, encoding='utf-8')\n",
        "\n",
        "print(f'Train Data Shape: {X.shape}\\nTest Data Shape: {X_test.shape}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data Shape: (26457, 18)\n",
            "Test Data Shape: (10000, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofKZYQ62xFAZ",
        "outputId": "69278d5c-7134-40a2-b7a1-33bb05e46993"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(X_train.shape, X_valid.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18519, 18) (7938, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d5OpeyVyUcn",
        "outputId": "15a1e230-2fe6-45b6-b1c5-652768213e00"
      },
      "source": [
        "cat_features = [i for i in X.columns if X[i].dtype == 'object']\n",
        "num_features = [i for i in X.columns if i not in cat_features + [target_col]]\n",
        "features = num_features + cat_features\n",
        "\n",
        "print(f'The Number of Categorical Features: {len(cat_features)}\\nThe Number of Numeric Features: {len(num_features)}\\nThe Number of Total Features: {len(features)}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Number of Categorical Features: 8\n",
            "The Number of Numeric Features: 10\n",
            "The Number of Total Features: 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viYzxmTu0un0",
        "outputId": "e6edab5d-b48e-453b-dca7-be1b303f2cf4"
      },
      "source": [
        "lde = LabelEncoder(min_obs=10)\n",
        "\n",
        "X_train[cat_features] = lde.fit_transform(X_train[cat_features])\n",
        "X_valid[cat_features] = lde.transform(X_valid[cat_features])\n",
        "X_test[cat_features] = lde.transform(X_test[cat_features])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1781: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item_labels[indexer[info_axis]]] = value\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr5s8qWL3Bvl",
        "outputId": "5eb5b8c5-89a2-4557-ef97-4470c07a7532"
      },
      "source": [
        "encoding_dim = 64\n",
        "\n",
        "def get_model(encoding_dim, dropout=0.2):\n",
        "    num_dim = len(num_features)\n",
        "    num_input = tf.keras.layers.Input((num_dim,), name='num_input')\n",
        "    cat_inputs = []\n",
        "    cat_embs = []\n",
        "    emb_dims = 0\n",
        "    for col in cat_features:\n",
        "        cat_input = tf.keras.layers.Input((1,), name=f'{col}_input')\n",
        "        emb_dim = max(8, int(np.log2(1 + X_train[col].nunique()) * 4))\n",
        "        cat_emb = tf.keras.layers.Embedding(input_dim=int(X_train[col].max()) + 1, output_dim=emb_dim)(cat_input)\n",
        "        cat_emb = tf.keras.layers.Dropout(dropout)(cat_emb)\n",
        "        cat_emb = tf.keras.layers.Reshape((emb_dim,))(cat_emb)\n",
        "\n",
        "        cat_inputs.append(cat_input)\n",
        "        cat_embs.append(cat_emb)\n",
        "        emb_dims += emb_dim\n",
        "\n",
        "    merged_inputs = tf.keras.layers.Concatenate()([num_input] + cat_embs)\n",
        "\n",
        "    encoded = tf.keras.layers.Dense(encoding_dim * 3, activation='relu')(merged_inputs)\n",
        "    encoded = tf.keras.layers.Dropout(dropout)(encoded)\n",
        "    encoded = tf.keras.layers.Dense(encoding_dim * 2, activation='relu')(encoded)\n",
        "    encoded = tf.keras.layers.Dropout(dropout)(encoded)    \n",
        "    encoded = tf.keras.layers.Dense(encoding_dim, activation='relu')(encoded)\n",
        "    \n",
        "    decoded = tf.keras.layers.Dense(encoding_dim * 2, activation='relu')(encoded)\n",
        "    decoded = tf.keras.layers.Dropout(dropout)(decoded)\n",
        "    decoded = tf.keras.layers.Dense(encoding_dim * 3, activation='relu')(decoded)\n",
        "    decoded = tf.keras.layers.Dropout(dropout)(decoded)    \n",
        "    decoded = tf.keras.layers.Dense(num_dim + emb_dims, activation='linear')(encoded)\n",
        "\n",
        "    encoder = tf.keras.Model([num_input] + cat_inputs, encoded)\n",
        "    ae = tf.keras.Model([num_input] + cat_inputs, decoded)\n",
        "    ae.add_loss(tf.keras.losses.mean_squared_error(merged_inputs, decoded))\n",
        "    ae.compile(optimizer='adam')\n",
        "\n",
        "    return ae, encoder\n",
        "\n",
        "ae, encoder = get_model(encoding_dim)\n",
        "ae.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "gender_input (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "car_input (InputLayer)          [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reality_input (InputLayer)      [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "income_type_input (InputLayer)  [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "edu_type_input (InputLayer)     [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "family_type_input (InputLayer)  [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "house_type_input (InputLayer)   [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "occyp_type_input (InputLayer)   [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_16 (Embedding)        (None, 1, 8)         16          gender_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "embedding_17 (Embedding)        (None, 1, 8)         16          car_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_18 (Embedding)        (None, 1, 8)         16          reality_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "embedding_19 (Embedding)        (None, 1, 10)        50          income_type_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "embedding_20 (Embedding)        (None, 1, 10)        50          edu_type_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "embedding_21 (Embedding)        (None, 1, 10)        50          family_type_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "embedding_22 (Embedding)        (None, 1, 11)        66          house_type_input[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "embedding_23 (Embedding)        (None, 1, 17)        323         occyp_type_input[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 1, 8)         0           embedding_16[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 1, 8)         0           embedding_17[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 1, 8)         0           embedding_18[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 1, 10)        0           embedding_19[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 1, 10)        0           embedding_20[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 1, 10)        0           embedding_21[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 1, 11)        0           embedding_22[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 1, 17)        0           embedding_23[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "num_input (InputLayer)          [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_16 (Reshape)            (None, 8)            0           dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_17 (Reshape)            (None, 8)            0           dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_18 (Reshape)            (None, 8)            0           dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_19 (Reshape)            (None, 10)           0           dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_20 (Reshape)            (None, 10)           0           dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_21 (Reshape)            (None, 10)           0           dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_22 (Reshape)            (None, 11)           0           dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_23 (Reshape)            (None, 17)           0           dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 92)           0           num_input[0][0]                  \n",
            "                                                                 reshape_16[0][0]                 \n",
            "                                                                 reshape_17[0][0]                 \n",
            "                                                                 reshape_18[0][0]                 \n",
            "                                                                 reshape_19[0][0]                 \n",
            "                                                                 reshape_20[0][0]                 \n",
            "                                                                 reshape_21[0][0]                 \n",
            "                                                                 reshape_22[0][0]                 \n",
            "                                                                 reshape_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 192)          17856       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 192)          0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 128)          24704       dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 128)          0           dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 64)           8256        dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 92)           5980        dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.convert_to_tensor_2 (TFOpLam (None, 92)           0           dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.cast_2 (TFOpLambda)          (None, 92)           0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.squared_difference_2 (T (None, 92)           0           tf.convert_to_tensor_2[0][0]     \n",
            "                                                                 tf.cast_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_mean_2 (TFOpLamb (None,)              0           tf.math.squared_difference_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "add_loss_2 (AddLoss)            (None,)              0           tf.math.reduce_mean_2[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 57,383\n",
            "Trainable params: 57,383\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjNsPKeS5Zbg",
        "outputId": "e684e45f-a990-4b44-d1bd-34ae5bf3c749"
      },
      "source": [
        "%%time\n",
        "\n",
        "inputs = [X_train[num_features].values] + [X_train[i].values for i in cat_features]\n",
        "\n",
        "ae.fit(inputs, inputs,\n",
        "       epochs=100,\n",
        "       batch_size=16384,\n",
        "       shuffle=True,\n",
        "       validation_split=0.2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 2s 2s/step - loss: 826332800.0000 - val_loss: 750382976.0000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 775452096.0000 - val_loss: 716517056.0000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 736558144.0000 - val_loss: 690145024.0000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 704710592.0000 - val_loss: 668436992.0000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 678923904.0000 - val_loss: 648667456.0000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 656338240.0000 - val_loss: 629012288.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 635182976.0000 - val_loss: 609877952.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 615788096.0000 - val_loss: 591292032.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 597640768.0000 - val_loss: 572020416.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 579132800.0000 - val_loss: 552107072.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 561146816.0000 - val_loss: 531534720.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 542880128.0000 - val_loss: 510389632.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 524184768.0000 - val_loss: 488776032.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 504969472.0000 - val_loss: 466660672.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 485483872.0000 - val_loss: 443402080.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 464579776.0000 - val_loss: 418687840.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 443443520.0000 - val_loss: 391289632.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 421750560.0000 - val_loss: 364025408.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 398567232.0000 - val_loss: 337518016.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 377038208.0000 - val_loss: 311443392.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 355104608.0000 - val_loss: 286508544.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 334366144.0000 - val_loss: 262606208.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 314782944.0000 - val_loss: 239932256.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 295843456.0000 - val_loss: 219195744.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 277402304.0000 - val_loss: 200481376.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 261711296.0000 - val_loss: 183782576.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 246916880.0000 - val_loss: 168800352.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 233020096.0000 - val_loss: 155085136.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 220401760.0000 - val_loss: 142759120.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 207793504.0000 - val_loss: 131495736.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 195740224.0000 - val_loss: 121149336.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 185104832.0000 - val_loss: 111599280.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 173649792.0000 - val_loss: 102481944.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 163635664.0000 - val_loss: 93658248.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 153392640.0000 - val_loss: 84914984.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 143459872.0000 - val_loss: 76252296.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 133330512.0000 - val_loss: 67721736.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 124351344.0000 - val_loss: 59397132.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 115108232.0000 - val_loss: 51620464.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 107577560.0000 - val_loss: 44519728.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 100303656.0000 - val_loss: 38260056.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 93562992.0000 - val_loss: 32942916.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 86636440.0000 - val_loss: 28572648.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 82558888.0000 - val_loss: 25039860.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 78479280.0000 - val_loss: 22188870.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 74600272.0000 - val_loss: 19872328.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 70884648.0000 - val_loss: 18001850.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 68051688.0000 - val_loss: 16521286.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 65671256.0000 - val_loss: 15352598.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 62862044.0000 - val_loss: 14454891.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 60277572.0000 - val_loss: 13759907.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 58584700.0000 - val_loss: 13186946.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 56777172.0000 - val_loss: 12615540.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 55093608.0000 - val_loss: 12016481.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 53774244.0000 - val_loss: 11379418.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 52172052.0000 - val_loss: 10723275.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 50626596.0000 - val_loss: 10061527.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 49499340.0000 - val_loss: 9415230.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 47608380.0000 - val_loss: 8838844.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 47230792.0000 - val_loss: 8350032.5000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 45721516.0000 - val_loss: 7942056.5000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 44442864.0000 - val_loss: 7624355.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 43400700.0000 - val_loss: 7413661.5000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 42793796.0000 - val_loss: 7286859.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 41763448.0000 - val_loss: 7186065.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 40984984.0000 - val_loss: 7032463.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 40348532.0000 - val_loss: 6825819.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 39778224.0000 - val_loss: 6607363.5000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 38771344.0000 - val_loss: 6343259.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 37400524.0000 - val_loss: 6069949.5000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 37137564.0000 - val_loss: 5805950.5000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 36520388.0000 - val_loss: 5491011.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 35547712.0000 - val_loss: 5192434.5000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 34971576.0000 - val_loss: 4921797.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 34699672.0000 - val_loss: 4710326.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 34135616.0000 - val_loss: 4596079.5000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 33610308.0000 - val_loss: 4537821.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 32308488.0000 - val_loss: 4473178.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 32477788.0000 - val_loss: 4389732.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 31961828.0000 - val_loss: 4265630.5000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 31696916.0000 - val_loss: 4124102.7500\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 30919618.0000 - val_loss: 3984363.5000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 30186066.0000 - val_loss: 3847715.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 30055442.0000 - val_loss: 3727248.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 29987058.0000 - val_loss: 3621680.7500\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 29537244.0000 - val_loss: 3585684.7500\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 28939238.0000 - val_loss: 3572238.7500\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 28762640.0000 - val_loss: 3572416.7500\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 28622418.0000 - val_loss: 3512565.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 27822306.0000 - val_loss: 3466084.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 27544092.0000 - val_loss: 3405502.7500\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 27399204.0000 - val_loss: 3376671.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 27083398.0000 - val_loss: 3307862.7500\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 26881982.0000 - val_loss: 3209638.5000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 26213678.0000 - val_loss: 3175471.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 26376022.0000 - val_loss: 3163492.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 25860804.0000 - val_loss: 3163410.7500\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 25310446.0000 - val_loss: 3126328.5000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 25585926.0000 - val_loss: 3051557.5000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 25228498.0000 - val_loss: 2940795.7500\n",
            "CPU times: user 9.84 s, sys: 443 ms, total: 10.3 s\n",
            "Wall time: 9.96 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_eAgYu8VYGO",
        "outputId": "160aad13-e460-4115-ba74-bba17781456d"
      },
      "source": [
        "features"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['child_num',\n",
              " 'income_total',\n",
              " 'DAYS_BIRTH',\n",
              " 'DAYS_EMPLOYED',\n",
              " 'FLAG_MOBIL',\n",
              " 'work_phone',\n",
              " 'phone',\n",
              " 'email',\n",
              " 'family_size',\n",
              " 'begin_month',\n",
              " 'gender',\n",
              " 'car',\n",
              " 'reality',\n",
              " 'income_type',\n",
              " 'edu_type',\n",
              " 'family_type',\n",
              " 'house_type',\n",
              " 'occyp_type']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPb_3iuC6NNR"
      },
      "source": [
        "def feature_ae(dataset):\n",
        "  inputs = [dataset[num_features].values] + [dataset[i].values for i in cat_features]\n",
        "  encoding = encoder.predict(inputs)\n",
        "  encoded = pd.concat([dataset[features], pd.DataFrame(encoding, columns=[f'enc_{i}' for i in range(encoding_dim)])], axis=1).reindex(dataset[features].index)\n",
        "\n",
        "  return encoded\n",
        "\n",
        "X_train_encoded = feature_ae(X_train)\n",
        "X_valid_encoded = feature_ae(X_valid)\n",
        "X_test_encoded = feature_ae(X_test)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQnz-jlh-WKe",
        "outputId": "22e7e762-7292-456e-ebfc-0141f85d9a00"
      },
      "source": [
        "X_train_encoded.shape, X_valid_encoded.shape, X_test_encoded.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((18519, 82), (7938, 82), (10000, 82))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "5SoAjfzdWCH3",
        "outputId": "5b52ddbe-fe84-4bf6-b50c-16f74537a8f5"
      },
      "source": [
        "X_train_encoded"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>child_num</th>\n",
              "      <th>income_total</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>FLAG_MOBIL</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>enc_0</th>\n",
              "      <th>enc_1</th>\n",
              "      <th>enc_2</th>\n",
              "      <th>enc_3</th>\n",
              "      <th>enc_4</th>\n",
              "      <th>enc_5</th>\n",
              "      <th>enc_6</th>\n",
              "      <th>enc_7</th>\n",
              "      <th>enc_8</th>\n",
              "      <th>enc_9</th>\n",
              "      <th>enc_10</th>\n",
              "      <th>enc_11</th>\n",
              "      <th>enc_12</th>\n",
              "      <th>enc_13</th>\n",
              "      <th>enc_14</th>\n",
              "      <th>enc_15</th>\n",
              "      <th>enc_16</th>\n",
              "      <th>enc_17</th>\n",
              "      <th>enc_18</th>\n",
              "      <th>enc_19</th>\n",
              "      <th>enc_20</th>\n",
              "      <th>enc_21</th>\n",
              "      <th>...</th>\n",
              "      <th>enc_24</th>\n",
              "      <th>enc_25</th>\n",
              "      <th>enc_26</th>\n",
              "      <th>enc_27</th>\n",
              "      <th>enc_28</th>\n",
              "      <th>enc_29</th>\n",
              "      <th>enc_30</th>\n",
              "      <th>enc_31</th>\n",
              "      <th>enc_32</th>\n",
              "      <th>enc_33</th>\n",
              "      <th>enc_34</th>\n",
              "      <th>enc_35</th>\n",
              "      <th>enc_36</th>\n",
              "      <th>enc_37</th>\n",
              "      <th>enc_38</th>\n",
              "      <th>enc_39</th>\n",
              "      <th>enc_40</th>\n",
              "      <th>enc_41</th>\n",
              "      <th>enc_42</th>\n",
              "      <th>enc_43</th>\n",
              "      <th>enc_44</th>\n",
              "      <th>enc_45</th>\n",
              "      <th>enc_46</th>\n",
              "      <th>enc_47</th>\n",
              "      <th>enc_48</th>\n",
              "      <th>enc_49</th>\n",
              "      <th>enc_50</th>\n",
              "      <th>enc_51</th>\n",
              "      <th>enc_52</th>\n",
              "      <th>enc_53</th>\n",
              "      <th>enc_54</th>\n",
              "      <th>enc_55</th>\n",
              "      <th>enc_56</th>\n",
              "      <th>enc_57</th>\n",
              "      <th>enc_58</th>\n",
              "      <th>enc_59</th>\n",
              "      <th>enc_60</th>\n",
              "      <th>enc_61</th>\n",
              "      <th>enc_62</th>\n",
              "      <th>enc_63</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1086</th>\n",
              "      <td>0.0</td>\n",
              "      <td>67500.0</td>\n",
              "      <td>-20900.0</td>\n",
              "      <td>365243.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50139.300781</td>\n",
              "      <td>26448.746094</td>\n",
              "      <td>66764.523438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79507.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30547.861328</td>\n",
              "      <td>61239.230469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50772.285156</td>\n",
              "      <td>29191.375000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37276.191406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30118.466797</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44514.304688</td>\n",
              "      <td>42751.816406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11386.277344</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55735.402344</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40014.980469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64791.933594</td>\n",
              "      <td>0.0</td>\n",
              "      <td>77837.039062</td>\n",
              "      <td>49872.828125</td>\n",
              "      <td>25089.023438</td>\n",
              "      <td>39540.691406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65773.015625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>106505.906250</td>\n",
              "      <td>51822.476562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54024.960938</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2993</th>\n",
              "      <td>0.0</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>-19408.0</td>\n",
              "      <td>-4553.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-58.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31597.000000</td>\n",
              "      <td>15440.605469</td>\n",
              "      <td>41550.953125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49190.222656</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17968.007812</td>\n",
              "      <td>37227.332031</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29968.673828</td>\n",
              "      <td>17506.375000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22887.421875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18107.826172</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26888.234375</td>\n",
              "      <td>25266.210938</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6940.037598</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33456.144531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23746.417969</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39448.160156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47440.824219</td>\n",
              "      <td>30989.353516</td>\n",
              "      <td>15758.159180</td>\n",
              "      <td>24412.089844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41315.796875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65505.957031</td>\n",
              "      <td>31649.472656</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32475.582031</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16219</th>\n",
              "      <td>0.0</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>-14279.0</td>\n",
              "      <td>-2939.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60650.476562</td>\n",
              "      <td>32128.652344</td>\n",
              "      <td>80745.515625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96225.046875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37040.703125</td>\n",
              "      <td>74189.468750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>61481.082031</td>\n",
              "      <td>35387.519531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45016.871094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36403.484375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53830.964844</td>\n",
              "      <td>51831.136719</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13799.448242</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67486.031250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48402.285156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78380.257812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94152.039062</td>\n",
              "      <td>60357.527344</td>\n",
              "      <td>30275.152344</td>\n",
              "      <td>47942.917969</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79497.679688</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128844.343750</td>\n",
              "      <td>62731.054688</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65416.269531</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14707</th>\n",
              "      <td>0.0</td>\n",
              "      <td>157500.0</td>\n",
              "      <td>-13783.0</td>\n",
              "      <td>-2058.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37461.480469</td>\n",
              "      <td>18860.722656</td>\n",
              "      <td>49524.113281</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58718.667969</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21888.298828</td>\n",
              "      <td>44716.652344</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36465.222656</td>\n",
              "      <td>21165.128906</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27442.574219</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21886.380859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32449.472656</td>\n",
              "      <td>30719.328125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8320.559570</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40404.351562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28838.593750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47415.082031</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57009.941406</td>\n",
              "      <td>36926.886719</td>\n",
              "      <td>18753.519531</td>\n",
              "      <td>29126.861328</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49041.078125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78420.382812</td>\n",
              "      <td>37980.617188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39222.664062</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4166</th>\n",
              "      <td>0.0</td>\n",
              "      <td>225000.0</td>\n",
              "      <td>-17915.0</td>\n",
              "      <td>-3366.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-44.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69032.921875</td>\n",
              "      <td>35564.640625</td>\n",
              "      <td>91508.187500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>108631.609375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41089.550781</td>\n",
              "      <td>83093.703125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68215.617188</td>\n",
              "      <td>39550.027344</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50726.832031</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40659.003906</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60366.109375</td>\n",
              "      <td>57575.820312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15408.041016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75233.148438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53787.160156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88002.882812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>105789.101562</td>\n",
              "      <td>68235.460938</td>\n",
              "      <td>34548.765625</td>\n",
              "      <td>53991.824219</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90238.765625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>145251.000000</td>\n",
              "      <td>70510.898438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73104.070312</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21575</th>\n",
              "      <td>3.0</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>-14838.0</td>\n",
              "      <td>-1539.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-47.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>1.0</td>\n",
              "      <td>69750.0</td>\n",
              "      <td>-10167.0</td>\n",
              "      <td>-829.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>42188.121094</td>\n",
              "      <td>21954.566406</td>\n",
              "      <td>56043.320312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66561.281250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25353.816406</td>\n",
              "      <td>51036.808594</td>\n",
              "      <td>0.0</td>\n",
              "      <td>42078.464844</td>\n",
              "      <td>24337.919922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31134.363281</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25040.064453</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37141.675781</td>\n",
              "      <td>35490.167969</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9460.568359</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46311.167969</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33166.171875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54056.085938</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64995.414062</td>\n",
              "      <td>41798.988281</td>\n",
              "      <td>21148.019531</td>\n",
              "      <td>33062.195312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55199.617188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89103.976562</td>\n",
              "      <td>43277.554688</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44978.062500</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.0</td>\n",
              "      <td>58500.0</td>\n",
              "      <td>-20657.0</td>\n",
              "      <td>365243.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52527.640625</td>\n",
              "      <td>26766.169922</td>\n",
              "      <td>69790.390625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82783.648438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31170.769531</td>\n",
              "      <td>63263.125000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52162.410156</td>\n",
              "      <td>29987.031250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39073.164062</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31337.169922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46202.472656</td>\n",
              "      <td>43727.144531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11804.741211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57516.402344</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41339.132812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67305.546875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80933.773438</td>\n",
              "      <td>52008.933594</td>\n",
              "      <td>26496.603516</td>\n",
              "      <td>40877.867188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69106.125000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>110914.195312</td>\n",
              "      <td>53730.171875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55732.449219</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15795</th>\n",
              "      <td>1.0</td>\n",
              "      <td>112500.0</td>\n",
              "      <td>-9811.0</td>\n",
              "      <td>-864.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27457.794922</td>\n",
              "      <td>12118.172852</td>\n",
              "      <td>35757.085938</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>42360.050781</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14733.046875</td>\n",
              "      <td>31322.849609</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25032.492188</td>\n",
              "      <td>14527.392578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20079.779297</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15439.423828</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22872.466797</td>\n",
              "      <td>20770.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6089.018066</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28505.582031</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20288.113281</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33531.566406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40654.085938</td>\n",
              "      <td>26820.044922</td>\n",
              "      <td>13881.305664</td>\n",
              "      <td>20653.863281</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36137.972656</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56178.179688</td>\n",
              "      <td>26752.908203</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27224.982422</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23654</th>\n",
              "      <td>0.0</td>\n",
              "      <td>315000.0</td>\n",
              "      <td>-14419.0</td>\n",
              "      <td>-2423.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18519 rows × 82 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       child_num  income_total  DAYS_BIRTH  ...  enc_61        enc_62  enc_63\n",
              "index                                       ...                              \n",
              "1086         0.0       67500.0    -20900.0  ...     0.0  54024.960938     0.0\n",
              "2993         0.0      180000.0    -19408.0  ...     0.0  32475.582031     0.0\n",
              "16219        0.0      180000.0    -14279.0  ...     0.0  65416.269531     0.0\n",
              "14707        0.0      157500.0    -13783.0  ...     0.0  39222.664062     0.0\n",
              "4166         0.0      225000.0    -17915.0  ...     0.0  73104.070312     0.0\n",
              "...          ...           ...         ...  ...     ...           ...     ...\n",
              "21575        3.0      135000.0    -14838.0  ...     NaN           NaN     NaN\n",
              "5390         1.0       69750.0    -10167.0  ...     0.0  44978.062500     0.0\n",
              "860          0.0       58500.0    -20657.0  ...     0.0  55732.449219     0.0\n",
              "15795        1.0      112500.0     -9811.0  ...     0.0  27224.982422     0.0\n",
              "23654        0.0      315000.0    -14419.0  ...     NaN           NaN     NaN\n",
              "\n",
              "[18519 rows x 82 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa-yrGzwP1AH",
        "outputId": "61180858-5471-4f0f-81a4-d80043437dc4"
      },
      "source": [
        "clf_xgb = XGBClassifier(verbosity=0, objective='multi:softprob', eval_metric='mlogloss')\n",
        "clf_xgb.fit(X_train_encoded, y_train, verbose=False)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
              "              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VKTu4mxXpHj",
        "outputId": "5ef0e439-536c-4b8c-ae76-82b281130110"
      },
      "source": [
        "y_pred = clf_xgb.predict_proba(X_valid_encoded)\n",
        "log_loss(y_true=y_valid, y_pred=y_pred)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8076105017208444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY8sIX_JYAVs"
      },
      "source": [
        "y_pred = clf_xgb.predict_proba(X_test_encoded)\n",
        "submission = pd.DataFrame(y_pred)\n",
        "submission['index'] = X_test.index\n",
        "submission = submission[['index', 0, 1, 2]]\n",
        "submission.to_csv('submission_0429_01.csv', encoding='utf-8', index=False)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROj3cY8V_Mf2",
        "outputId": "a3619268-03ac-42bb-c171-c6902eb8d1a1"
      },
      "source": [
        "%%time\n",
        "\n",
        "space = {\n",
        "    'learning_rate': hp.quniform('learning_rate', 0.01, 0.1, 0.01)\n",
        "}\n",
        "\n",
        "\n",
        "def objective(space):\n",
        "    clf_xgb = XGBClassifier(learning_rate=space['learning_rate'],\n",
        "                            verbosity=0,\n",
        "                            objective='multi:softprob',\n",
        "                            eval_metric='mlogloss')\n",
        "    \n",
        "    clf_xgb.fit(X_train_encoded, y_train, early_stopping_rounds=10, eval_set=[(X_valid_encoded, y_valid)], verbose=False)\n",
        "    scores = cross_val_score(estimator=clf_xgb, X=X_train_encoded, y=y_train, cv=5, scoring='neg_log_loss')\n",
        "    cv_mean = scores.mean()\n",
        "    \n",
        "    return {'loss': 1 - cv_mean, 'status': STATUS_OK}\n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=30,\n",
        "            trials=trials)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 5/30 [06:14<31:09, 74.80s/it, best loss: 1.8009957753667325]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}